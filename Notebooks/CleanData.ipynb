{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f0b645-7b0e-4ed9-bd43-4db1dc8c93a6",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2f9ac-2bd7-49b2-a58b-15278a08e833",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Translate subject names to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9f5f670-9673-4a55-ab69-926b9c174c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_translation = {\n",
    "    \"Matemática e suas Tecnologias\": \"Mathematics\",\n",
    "    \"Linguagens, Códigos e suas Tecnologias\": \"Languages\",\n",
    "    \"Ciências Humanas e suas Tecnologias\": \"Human Sciences\",\n",
    "    \"Ciências da Natureza e suas Tecnologias\": \"Natural Sciences\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72c976-4df0-4446-a195-886132027770",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Process files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2fbbd303-bd49-41db-9114-f1e9042bfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_files(raw_dir, cleaned_dir, file_prefix, cleaning_func):\n",
    "    \"\"\"\n",
    "    Iterates over CSV files in raw_dir that match the given file_prefix.\n",
    "    For each file, it checks if the cleaned version exists in cleaned_dir.\n",
    "    If not, it applies cleaning_func to create a cleaned DataFrame and saves it.\n",
    "    \n",
    "    Parameters:\n",
    "      raw_dir (str): Directory containing the raw CSV files.\n",
    "      cleaned_dir (str): Directory where cleaned CSV files will be saved.\n",
    "      file_prefix (str): The prefix part of the filename (e.g., \"cove_few-shot_results\").\n",
    "      cleaning_func (function): A function that takes a DataFrame and returns a cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure the cleaned directory exists.\n",
    "    os.makedirs(cleaned_dir, exist_ok=True)\n",
    "    \n",
    "    # Build a regex pattern for filenames using the provided prefix.\n",
    "    # It expects filenames like <file_prefix>_YYYY-MM-DD_HH-MM-SS.csv.\n",
    "    pattern = re.compile(\n",
    "        rf'({re.escape(file_prefix)})_(\\d{{4}}-\\d{{2}}-\\d{{2}}_\\d{{2}}-\\d{{2}}-\\d{{2}})\\.csv'\n",
    "    )\n",
    "    \n",
    "    for filename in os.listdir(raw_dir):\n",
    "        if not filename.endswith(\".csv\"):\n",
    "            continue\n",
    "        \n",
    "        match = pattern.match(filename)\n",
    "        if not match:\n",
    "            print(f\"Filename does not match pattern: {filename}\")\n",
    "            continue\n",
    "        \n",
    "        base_name = match.group(1)\n",
    "        timestamp = match.group(2)\n",
    "        # Construct the cleaned filename.\n",
    "        cleaned_filename = f\"{base_name}_clean_{timestamp}.csv\"\n",
    "        cleaned_filepath = os.path.join(cleaned_dir, cleaned_filename)\n",
    "        \n",
    "        if os.path.exists(cleaned_filepath):\n",
    "            print(f\"Cleaned file already exists: {cleaned_filename}\")\n",
    "            continue\n",
    "        \n",
    "        raw_filepath = os.path.join(raw_dir, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(raw_filepath)\n",
    "            # Apply the cleaning function.\n",
    "            cleaned_df = cleaning_func(df)\n",
    "            # Save the cleaned DataFrame.\n",
    "            cleaned_df.to_csv(cleaned_filepath, index=False)\n",
    "            print(f\"Processed and saved cleaned file: {cleaned_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296daf84-d935-4c96-8114-92a4bdbeae57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Self-Refine cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "018480dc-b971-4475-b815-0e258266e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer_letter(response):\n",
    "    # Match \"Resposta final: C)\" or \"Resposta final: C\"\n",
    "    match = re.search(r\"resposta final\\s*[:\\-]?\\s*([A-E])\\s*\\)?\", response, re.IGNORECASE | re.DOTALL)\n",
    "    if not match:\n",
    "        # Try fallback patterns\n",
    "        match = re.search(r\"letra\\s+([A-E])\\b\", response, re.IGNORECASE)\n",
    "    return match.group(1).upper() if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f66d2c3-b4b2-4865-b317-3fc362ee08ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_self_refine(df):\n",
    "    # If \"initial_answer\" column exists, use it.\n",
    "    if \"initial_answer\" in df.columns:\n",
    "        initial_answer_series = df[\"initial_answer\"]\n",
    "    # Otherwise, if \"baseline_answer\" exists, create \"initial_answer\" by applying extract_answer_letter.\n",
    "    elif \"baseline_answer\" in df.columns:\n",
    "        initial_answer_series = df[\"baseline_answer\"].apply(extract_answer_letter)\n",
    "    else:\n",
    "        # If neither column is present, set initial_answer_series to None\n",
    "        initial_answer_series = None\n",
    "\n",
    "    cleaned_df = pd.DataFrame({\n",
    "        \"id\": df[\"id\"],\n",
    "        \"subject\": df[\"subject\"].map(subject_translation),\n",
    "        \"ground_truth\": df[\"ground_truth\"],\n",
    "        \"predicted\": df[\"predicted\"],\n",
    "        \"correct\": df[\"correct\"],\n",
    "        \"initial_answer\": initial_answer_series\n",
    "    })\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b963c6ed-de12-43d6-aae0-c148225b286b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CoVe cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d349be72-bdde-45e5-af2f-93c429f10bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cove(df):\n",
    "    \"\"\"\n",
    "    Cleaning function for the cove method.\n",
    "    Keeps an extra column 'initial_answer'.\n",
    "    \"\"\"\n",
    "    cleaned_df = pd.DataFrame({\n",
    "        \"id\": df[\"id\"],\n",
    "        \"subject\": df[\"subject\"].map(subject_translation),\n",
    "        \"ground_truth\": df[\"ground_truth\"],\n",
    "        \"predicted\": df[\"predicted\"],\n",
    "        \"correct\": df[\"correct\"],\n",
    "        \"initial_answer\": df[\"initial_answer\"]\n",
    "    })\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd88df-06f8-4f35-a5f1-eb043e6e1bcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CoT cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e1a47dd3-0a7f-4bcd-a8b7-f465088df5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cot(df):\n",
    "    \"\"\"\n",
    "    Cleaning function for the cot method.\n",
    "    Omits the 'initial_answer' column.\n",
    "    \"\"\"\n",
    "    cleaned_df = pd.DataFrame({\n",
    "        \"id\": df[\"id\"],\n",
    "        \"subject\": df[\"subject\"].map(subject_translation),\n",
    "        \"ground_truth\": df[\"ground_truth\"],\n",
    "        \"predicted\": df[\"predicted\"],\n",
    "        \"correct\": df[\"correct\"]\n",
    "    })\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95013ba-5daa-445f-9d15-600104cc8e41",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae300883-5400-4773-b191-95995269ab05",
   "metadata": {},
   "source": [
    "### CoVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db3411c2-fd8e-466d-8daf-de7aa9fdf910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file already exists: cove_few-shot_results_clean_2025-04-01_02-41-38.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-31_04-12-49.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-28_17-19-55.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-30_20-51-22.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-30_18-11-48.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-30_23-08-43.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-04-01_07-45-02.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-30_15-33-09.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-31_16-41-31.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-28_12-04-04.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-30_19-30-48.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-30_16-53-21.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-31_21-35-51.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-30_14-05-35.csv\n",
      "Cleaned file already exists: cove_few-shot_results_clean_2025-03-27_14-42-13.csv\n"
     ]
    }
   ],
   "source": [
    "raw_dir_cove = \"results/cove_few-shot\"\n",
    "cleaned_dir_cove = \"results/cove_few-shot_clean\"\n",
    "process_files(raw_dir_cove, cleaned_dir_cove, \"cove_few-shot_results\", clean_cove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf6df4b-9a51-4b30-8bad-4b41b3cdf912",
   "metadata": {},
   "source": [
    "### CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "472f765d-522d-4ba5-9391-4604d7d08ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-31_11-28-31.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-31_11-07-13.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-31_18-37-21.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-31_01-11-32.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-30_14-38-11.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-28_11-16-41.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-30_18-47-39.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-04-01_04-43-47.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-30_20-07-08.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-31_11-14-23.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-30_13-24-37.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-04-01_09-50-21.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-31_11-21-40.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-30_16-07-22.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-30_17-26-58.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-31_13-50-04.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-30_21-24-56.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-27_13-55-58.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-31_23-41-17.csv\n",
      "Cleaned file already exists: cot_few-shot_results_clean_2025-03-28_16-26-01.csv\n"
     ]
    }
   ],
   "source": [
    "raw_dir_cot = \"results/cot_few-shot\"\n",
    "cleaned_dir_cot = \"results/cot_few-shot_clean\"\n",
    "process_files(raw_dir_cot, cleaned_dir_cot, \"cot_few-shot_results\", clean_cot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e804ae-c10d-4759-8637-55c45b16a1c5",
   "metadata": {},
   "source": [
    "### Self-Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3865e5c-354b-49af-82ec-d690dc96a7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-04-01_04-17-46.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-31_18-12-53.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-27_15-08-17.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-30_19-59-42.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-30_17-20-05.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-04-01_09-24-29.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-28_12-33-28.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-31_23-15-22.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-30_21-17-41.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-30_14-31-20.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-31_11-23-02.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-30_15-59-59.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-31_00-45-38.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-31_05-49-34.csv\n",
      "Cleaned file already exists: self-refine_few-shot_results_clean_2025-03-30_18-38-48.csv\n"
     ]
    }
   ],
   "source": [
    "raw_dir_self_refine = \"results/self-refine_few-shot\"\n",
    "cleaned_dir_self_refine = \"results/self-refine_few-shot_clean\"\n",
    "process_files(raw_dir_self_refine, cleaned_dir_self_refine, \"self-refine_few-shot_results\", clean_self_refine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bthesis)",
   "language": "python",
   "name": "bthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
